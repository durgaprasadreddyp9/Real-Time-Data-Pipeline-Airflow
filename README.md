# â³ Real-Time Data Ingestion Pipeline with Apache Airflow, PostgreSQL, and API Integration

## ğŸ“Œ Overview
This project implements a **real-time data ingestion pipeline** using **Apache Airflow**. The pipeline extracts user data from an API, processes it into a structured format, and loads it into a **PostgreSQL** database. Additionally, weather data is retrieved from another API and integrated into the database. The entire process is **automated with Airflow**, and **DBWeaver** is used for database visualization.


### ğŸ”¹ Components
- **ğŸŒ API Data Source**: REST APIs providing user and weather data in JSON format.
- **âš¡ Apache Airflow**: Orchestrates the entire ETL (Extract, Transform, Load) process.
- **ğŸ—„ PostgreSQL**: Stores the structured user and weather data.
- **ğŸ“Š DBWeaver**: Used for managing and visualizing PostgreSQL data.
- **ğŸ³ Docker**: Containerizes the Airflow environment for seamless deployment.

---

## ğŸ”„ Workflow

### **1ï¸âƒ£ Extract User Data**
- The **SimpleHttpOperator** in Airflow fetches user data from an external API.
- The API response is parsed and stored as an **XCom variable**.

### **2ï¸âƒ£ Extract Weather Data**
- Another **SimpleHttpOperator** fetches real-time weather data from an external API.
- The response is stored as an **XCom variable** for further processing.

### **3ï¸âƒ£ Process Data**
- The extracted JSON data is **transformed** into a structured format using **Pandas**.
- The data is **normalized** and converted into **CSV format** for efficient loading.

### **4ï¸âƒ£ Store Data**
- A **PostgresHook** is used to load the processed CSV data into a **PostgreSQL database**.
- The **COPY SQL command** ensures efficient data insertion.

---

## ğŸš€ Getting Started

### ğŸ”§ Prerequisites
Ensure you have the following installed:
- **Docker** ğŸ³
- **Apache Airflow** âš¡
- **PostgreSQL** ğŸ—„
- **Python (>=3.8)** ğŸ
- **DBWeaver** (Optional for visualization) ğŸ“Š




